\# ğŸš€ Big Data Ateliers â€“ Complete Hadoop Ecosystem \<div
align="center"\> \<img
src="https://img.shields.io/badge/Docker-ready-blue?logo=docker"\> \<img
src="https://img.shields.io/badge/Hadoop-3.x-yellow?logo=apache"\> \<img
src="https://img.shields.io/badge/Hive-SQL-orange?logo=apachehive"\>
\<img
src="https://img.shields.io/badge/Pig-Scripting-lightgrey?logo=apache"\>
\<img src="https://img.shields.io/badge/License-MIT-green"\>
\<br\>\<br\> A complete Hadoop ecosystem lab with 6 ateliers to practice
HDFS, MapReduce, Pig, Hive, file formats, and partitioning. Everything
runs in Docker for simplicity and reproducibility. ğŸ”¹ Quick Start â€¢ ğŸ”¹
Ateliers â€¢ ğŸ”¹ Architecture â€¢ ğŸ”¹ Progress \</div\> --- \## ğŸ“‹ Table of
Contents - ğŸŒŸ Overview - ğŸ— Architecture - âš¡ Quick Start - ğŸ¯ Ateliers -
ğŸ“Š Progress Tracker - ğŸ¤ Contributing - ğŸ“ License --- \## ğŸŒŸ Overview
Welcome to the Big Data Learning Journey! This project provides a
comprehensive Hadoop learning environment with 6 hands-on ateliers
covering the entire big data processing pipeline: \| ğŸ§ª Module \| ğŸ”§
Technology \| ğŸ¯ Focus Area \|
\|--------------\|---------------\|---------------------------\| \| ğŸ“
Atelier 1 \| HDFS \| Distributed File System \| \| âš™ï¸ Atelier 2 \|
MapReduce \| Distributed Processing \| \| ğŸ– Atelier 3 \| Pig \| Data
Flow Scripting \| \| ğŸ Atelier 4 \| Hive \| SQL Data Warehousing \| \|
ğŸ’¾ Atelier 5 \| Hive \| Storage Optimization \| \| ğŸš€ Atelier 6 \| Hive
\| Query Performance \| --- \## ğŸ— Architecture \`\`\`mermaid flowchart
TD Client\[ğŸ’» Client\] --\> NN\[Namenode\] NN --\>\|Stores metadata\|
DNs\[Datanodes\] DNs --\>\|Stores blocks\| HDFS\[(HDFS Storage)\] HDFS
--\> MR\[âš™ï¸ MapReduce\] MR --\> Pig\[ğŸ– Pig Scripts\] MR --\> Hive\[ğŸ
Hive SQL\] style Client fill:#e1f5fe style NN fill:#f3e5f5 style DNs
fill:#e8f5e8 style HDFS fill:#fff3e0 ğŸ”§ Prerequisites ğŸ³ Docker & Docker
Compose ğŸ“¦ Git ğŸ’» 4GB+ RAM available ğŸš€ Deployment Steps \# ğŸ“¥ Clone
repository git clone
https://github.com/your-org/hadoop-ecosystem-ateliers.git cd
hadoop-ecosystem-ateliers \# ğŸ— Build and start the cluster docker
compose up -d --build \# ğŸ”‘ Access the namenode container docker exec
-it namenode bash \# ğŸ“ Prepare HDFS directory structure hdfs dfs -mkdir
-p /ateliers/{atelier1,atelier2,atelier3,atelier4,atelier5,atelier6} \#
ğŸ“¤ Upload datasets to HDFS for i in {1..6}; do hdfs dfs -put
/ateliers_local/atelier\$i/\* /ateliers/atelier\$i/ done \# âœ… Verify
setup hdfs dfs -ls -R /ateliers ğŸ” System Verification \# ğŸ“Š Check HDFS
status hdfs dfsadmin -report \# ğŸ³ Verify services are running docker ps
\# ğŸ” Test basic HDFS operations hdfs dfs -ls / ğŸ¯ Ateliers 1ï¸âƒ£ Atelier 1
â€“ HDFS Basics hdfs dfs -ls /ateliers/atelier1/ hdfs dfs -cat
/ateliers/atelier1/input/FL_insurance.csv \| head -3 hdfs dfsadmin
-report \| head -20 hdfs fsck /ateliers/atelier1 -blocks -locations
Learning Objectives: ğŸ“ HDFS file navigation and inspection ğŸ§± Block
storage concepts ğŸ“Š Cluster monitoring and reporting 2ï¸âƒ£ Atelier 2 â€“
MapReduce hdfs dfs -mkdir -p /ateliers/atelier2/wordcount/{input,output}
hdfs dfs -put /ateliers/atelier2/maman.txt
/ateliers/atelier2/wordcount/input/ javac -cp \$(hadoop classpath) -d
build WordCount.java jar -cvf wordcount.jar -C build/ . hadoop jar
wordcount.jar WordCount \\ /ateliers/atelier2/wordcount/input \\
/ateliers/atelier2/wordcount/output hdfs dfs -cat
/ateliers/atelier2/wordcount/output/part-r-00000 \| head -10 Learning
Objectives: âš™ï¸ MapReduce programming model ğŸ— Java compilation and JAR
packaging ğŸ“Š Job submission and monitoring 3ï¸âƒ£ Atelier 3 â€“ Pig pig -x
local \<\< 'EOF' vols = LOAD '/ateliers/atelier3/vol.csv' USING
PigStorage(';') AS (year:int, month:int, day:int, flight:chararray,
depart:chararray, destination:chararray, distance:int); departure_counts
= FOREACH (GROUP vols BY depart) GENERATE group AS airport, COUNT(vols)
AS flight_count; STORE departure_counts INTO
'/ateliers/atelier3/pig_output/departure_counts'; quit; EOF hdfs dfs
-cat /ateliers/atelier3/pig_output/departure_counts/part-r-00000
Learning Objectives: ğŸ“ Pig Latin syntax and data flow ğŸ”„ Data
transformation and aggregation âš¡ Script execution modes 4ï¸âƒ£ Atelier 4 â€“
Hive Basics CREATE DATABASE IF NOT EXISTS atelier4; USE atelier4; CREATE
EXTERNAL TABLE vols ( year INT, month INT, day INT, flight STRING,
depart STRING, destination STRING, distance INT ) ROW FORMAT DELIMITED
FIELDS TERMINATED BY ';' LOCATION '/ateliers/atelier4/'; SELECT depart,
COUNT(\*) as flight_count FROM vols GROUP BY depart ORDER BY
flight_count DESC LIMIT 10; SELECT depart, destination, AVG(distance) as
avg_distance FROM vols GROUP BY depart, destination LIMIT 10; Learning
Objectives: ğŸ— Hive table creation and management ğŸ“Š SQL queries on
structured data ğŸ”— External tables and data location mapping 5ï¸âƒ£ Atelier
5 â€“ Hive File Formats USE atelier5; CREATE EXTERNAL TABLE bank_txt ( id
INT, age INT, sex STRING, region STRING, income DOUBLE ) ROW FORMAT
DELIMITED FIELDS TERMINATED BY ',' LOCATION '/ateliers/atelier5/';
CREATE TABLE bank_parquet STORED AS PARQUET AS SELECT \* FROM bank_txt;
SELECT region, AVG(income) as avg_income FROM bank_txt GROUP BY region;
SELECT region, AVG(income) as avg_income FROM bank_parquet GROUP BY
region; DESC FORMATTED bank_txt; DESC FORMATTED bank_parquet; Learning
Objectives:

ğŸ’¾ Storage format comparison (Text vs Parquet)

âš¡ Performance benchmarking

ğŸš€ Storage optimization techniques

6ï¸âƒ£ Atelier 6 â€“ Hive Partitioning USE atelier6;

CREATE TABLE bank_partitioned ( id INT, age INT, sex STRING, income
DOUBLE ) PARTITIONED BY (region STRING) ROW FORMAT DELIMITED FIELDS
TERMINATED BY ',';

SET hive.exec.dynamic.partition = true; SET
hive.exec.dynamic.partition.mode = nonstrict;

INSERT OVERWRITE TABLE bank_partitioned PARTITION(region) SELECT id,
age, sex, income, region FROM atelier5.bank_txt;

SELECT COUNT(\*) FROM bank_partitioned WHERE region = 'Europe';

SHOW PARTITIONS bank_partitioned; ANALYZE TABLE bank_partitioned COMPUTE
STATISTICS; Learning Objectives:

ğŸ—‚ Partitioning concepts and benefits

âš¡ Dynamic partitioning setup

ğŸš€ Query optimization with partitions ğŸ“Š Progress Tracker \# Atelier
Topic Status Difficulty 1ï¸âƒ£ Atelier 1 HDFS Basics âœ… Completed ğŸŸ¢
Beginner 2ï¸âƒ£ Atelier 2 MapReduce âœ… Completed ğŸŸ¡ Intermediate 3ï¸âƒ£ Atelier
3 Pig Scripting âœ… Completed ğŸŸ¡ Intermediate 4ï¸âƒ£ Atelier 4 Hive Basics âœ…
Completed ğŸŸ¢ Beginner 5ï¸âƒ£ Atelier 5 Hive File Formats âœ… Completed ğŸŸ¡
Intermediate 6ï¸âƒ£ Atelier 6 Hive Partitioning âœ… Completed ğŸ”´ Advanced
